## TIER 3 TEMPLATE: METHODOLOGY FRAMEWORK

**File:** `madio_template_tier3_methodology_framework.md`


**Document Authority:** TIER 3 - SUPPORTING SPECIFICATION
**Document Type:** methodology_framework
**Version:** 1.0
**Created:** [DATE]
**Last Modified:** [DATE]
**Reports To:** orchestrator

---

## OVERVIEW

**Tier:** 3
**Purpose:** To provide a standardized, systematic, [N]-step methodology for conducting complex analysis or implementation projects. This framework ensures a structured process from initial data gathering to actionable recommendations and reporting, applicable across any [DOMAIN].

---

## CRITICAL USAGE INSTRUCTION

This document outlines the required [N]-step process for all major analytical and implementation tasks. Adherence to this methodology is mandatory to ensure consistency, quality, and alignment with the project's strategic goals. Each step must be completed in sequence unless explicitly permitted by the `orchestrator`.

---

## HIERARCHICAL CONTEXT

This Tier 3 `methodology_framework` provides the detailed "how-to" for the analysis and solution phases outlined by the Tier 2 `orchestrator`. It relies on the `Evaluation Rubrics` and `Strategic Framework` documents for specific evaluation criteria and strategic assessment.

---

## WHEN TO USE

Use this template when you need to:
- Conduct a comprehensive analysis of a [SYSTEM], [PRODUCT], or [PROCESS].
- Develop a structured implementation plan for a new initiative.
- Diagnose the root causes of performance issues in any [DOMAIN].
- Create a standardized, evidence-based report for [TARGET_ROLE] and other stakeholders.

---

## INTEGRATION REQUIREMENTS

- **Inputs:** Requires initial context and inputs as defined in Step 1, often provided by the `orchestrator` or a `[PROJECT]_brief` document.
- **Dependencies:** Must be used in conjunction with the `madio_template_tier3_rubrics_evaluation.md` for evaluation criteria (Step 3) and the `madio_template_tier3_strategic_framework.md` for strategic verification (Step 4).
- **Outputs:** The final output is a structured report or deliverable as defined in Step 8, which serves as a key input for project execution and stakeholder communication.

---

# [PROJECT_NAME]: [N]-Step Methodology Framework

## Introduction

This methodology provides a structured approach for analyzing an existing [SYSTEM/PROCESS] within a specific [INDUSTRY/DOMAIN], based on reviewing [KEY_ASSETS] and other available information. It adapts a comprehensive development framework into an analysis-focused methodology.

### Key Terminology
- **Observations:** In Steps 1–3, capture objective facts and artifacts illustrating the current state.
- **Root Cause Findings:** In Step 4, synthesize observations into systemic issues that explain underlying challenges.
- **Strategic Recommendations:** In Step 5, propose initiatives that address the root causes.
- **Quick Wins:** High-impact, low-effort changes implementable in a short timeframe (e.g., 30–60 days).
- **Strategic Initiatives:** Broader transformations requiring deeper resource commitment (e.g., 60–120+ days).

---

## Analysis Framework Overview

### Interconnected [EVALUATION_DIMENSIONS] Model
This methodology examines [N] core dimensions that work as an interconnected system. Understanding these relationships is essential for accurate diagnosis and effective remediation.

### The [N]-Step Methodology Process
The methodology follows a structured [N]-step process that systematically moves from information gathering to actionable recommendations.

- **Discovery Phase (Steps 1-3):** Build a comprehensive understanding before diagnosing.
- **Strategic Verification (Between Steps 3-4):** Ensure critical strategic elements are identified.
- **Analysis Phase (Step 4):** Connect symptoms to root causes and map cross-dimensional impacts.
- **Solution Phase (Steps 5-7):** Transform insights into structured action plans with validation.
- **Communication Phase (Step 8):** Package findings for maximum stakeholder value.

---

## SECTION 1: The [N]-Step Methodology

### **STEP 1: Initial Context & Input Capture**
**Objective:** Build foundational context. Understand the subject's identity, operational model, and perceived environment to ensure analysis is properly aligned.

**1.1 Information Gathering Protocol:**
- **Required Information Sources:**
  - Primary Subject Asset (e.g., [WEBSITE], [APPLICATION], [PROCESS_DOCUMENTATION])
  - User-provided `[PROJECT]_brief` or equivalent foundational input document.
  - Internal documentation and stakeholder interviews.
  - Publicly available data (e.g., press releases, industry reports).
- **Verification Process:**
  - Cross-reference information across sources.
  - Note inconsistencies or contradictions.
  - Flag missing elements for investigation.

**1.2 Profile Capture:**
- **Subject Name:** [Insert name of system, product, or process]
- **Key Identifiers:** [Primary URL, version number, etc.]
- **Industry/Domain:** [Specific vertical or focus]
- **Key Stakeholders:** [Owners, users, decision-makers]

**1.3 Overview Documentation:**
- **Primary Function:** What specific jobs does the subject perform?
- **Key Components:** Core features, technologies, or process steps.
- **Operational Model:** How is it delivered, used, or executed?

**1.4 Target Audience/User Context:**
- **Ideal User Profile (IUP):** Who is the explicitly stated or implicitly targeted user?
- **Pain Points Addressed:** Stated challenges or inefficiencies the subject solves.
- **Decision-Maker vs. User:** Differentiate between buyers/approvers and end-users.

**1.5 Competitive & Market Framing:**
- **Named Competitors/Alternatives:** Direct alternatives explicitly mentioned.
- **Differentiation Claims:** Key assertions of uniqueness or advantage.

---

### **STEP 2: Evidence Collection Protocol**
**Objective:** Establish a high-integrity, reproducible signal collection process that fuels reliable evaluation across all [EVALUATION_DIMENSIONS].

**2.1 Data Quality Protocol:**
- **Source Prioritization:** Define tiers of source reliability (e.g., Tier 1: Official documentation, Tier 2: Stakeholder interviews, Tier 3: Third-party analysis).
- **Exclusion Rules:** Define what sources to exclude (e.g., unverified commentary, outdated information).
- **Citation Format:** Use a consistent format for all evidence, e.g., `"[Evidence]" — [Source: Location/URL] (Accessed: [DATE])`.

**2.2 Artifact Audit Checklist:**
- Primary Subject Asset(s)
- User-provided `[PROJECT]_brief`
- Third-party reviews or audits
- Internal reports and analytics
- Stakeholder interviews and feedback
- Competitor/Alternative assets for comparison

**2.3 Search Instruction Examples:**
- `"[SUBJECT_NAME] reviews"`
- `"[SUBJECT_NAME] case studies"`
- `"[SUBJECT_NAME] vs [ALTERNATIVE]"`
- `"[INDUSTRY] best practices for [PROCESS]"`

**2.4 AI-Guided Extraction Prompts:**
- **Value Check:** "What is the main pain point this [SUBJECT] claims to solve? Who is the target user?"
- **Effectiveness Review:** "What is the primary call-to-action or next step? Is it frictionless and appropriate for the user's intent?"
- **Differentiation Clarity:** "What makes this [SUBJECT] different from its alternatives? Is the positioning clear and ownable?"

---

### **STEP 3: [FRAMEWORK_COMPONENT] Evaluation Using [EVALUATION_TOOL]**
**Objective:** Translate raw evidence into structured, rubric-aligned assessments for each of the [N] [EVALUATION_DIMENSIONS].
**Note:** Scoring criteria are maintained in the companion `Evaluation Rubrics` document.

**3.1 Dimensions Assessed:**
1. [DIMENSION_1_NAME] (e.g., Strategic Alignment & Messaging)
2. [DIMENSION_2_NAME] (e.g., User Journey & Experience)
3. [DIMENSION_3_NAME] (e.g., Market Presence & Visibility)
4. ...and so on for all [N] dimensions.

**3.2 Evaluation Process:**
- Refer to the `Evaluation Rubrics` document for detailed criteria.
- For each dimension, compare the collected evidence against the performance level descriptions (e.g., Exceptional, Competent, Needs Work, Critical Gap).
- Assign a rating and document the specific evidence supporting it.

**3.3 Format for Dimension Scoring:**
- **[Dimension Name]**
- **Rating:** [Exceptional / Competent / Needs Work / Critical Gap]
- **Strengths:** [List strong practices backed by evidence.]
- **Opportunities:** [List gaps, risks, or weak areas.]
- **Notes:** [Add analytical commentary or context.]

---

### **STEP 4: Root Cause Analysis**
**Objective:** Synthesize dimensional observations into 3–5 strategic breakdowns that explain the root causes of performance gaps.
**Note:** Before finalizing, verify against the `Strategic Framework` document to ensure all critical strategic opportunities are evaluated.

**4.1 Root Cause Discovery Process:**
- Review all observations from Step 3.
- Identify recurring issues that manifest across multiple dimensions.
- Use the user-provided `[PROJECT]_brief` to inform hypotheses about underlying drivers.
- Cluster related observations into root cause themes (e.g., Misaligned User Profile, Flawed Value Proposition, Gaps in User Journey).

**4.2 Documentation Format:**
- **Root Cause:** [Title of Theme]
- **Business/Project Impact:** [Concise explanation of how this affects project goals.]
- **Description:** [Short summary of the strategic issue.]
- **Supporting Evidence:** [List of quotes or observations with sources.]
- **Implications:** [Detail specific risks if unaddressed.]

---

### **STEP 5: Strategic Recommendations**
**Objective:** Develop targeted initiatives that directly address the prioritized root causes identified in Step 4.

**5.1 Recommendation Format:**
- **Recommendation:** [Title or Action Label]
- **Root Cause Addressed:** [Reference from Step 4]
- **Rationale:** [Explain why this action matters and connect it to project goals and impact.]
- **Implementation Actions:** [Provide step-by-step tactical moves, team/resource assignments, and timeline estimates.]
- **Supporting Evidence:** [Cite the evidence that justifies this recommendation.]

**5.2 Types of Recommendations:**
- **Strategic Repositioning:** Refine core messaging to reflect user pain points and value.
- **User Journey Fixes:** Add middle-stage content or clearer calls-to-action.
- **Validation Reinforcement:** Add social proof, testimonials, or case studies.
- **Competitive Differentiation:** Create content that clearly frames advantages over alternatives.
- **Visibility Enhancements:** Implement [SEO/DISCOVERY]-targeted updates.

---

### **STEP 6: Prioritization Matrix**
**Objective:** Categorize all recommendations into a visual 2x2 framework to guide execution priorities.

**6.1 Matrix Structure:**
- **Axes:** Impact vs. Effort
- **Quadrants:**
  - **High Impact, Low Effort:** Quick Wins
  - **High Impact, High Effort:** Strategic Initiatives
  - **Low Impact, Low Effort:** Minor Fixes
  - **Low Impact, High Effort:** Deprioritize / Avoid

**6.2 Process:**
- Evaluate each recommendation from Step 5 for its relative impact and effort.
- Assign each recommendation to a quadrant and provide a brief justification.

---

### **STEP 7: Phased Implementation Plan**
**Objective:** Translate strategic recommendations into a sequenced rollout plan across focused phases.

**Phase 1: Foundational Fixes & Data Collection (e.g., Weeks 1–2)**
- **Goal:** Establish baselines and address critical gaps.
- **Key Initiatives:** Execute evidence collection, score all dimensions, fix critical errors.

**Phase 2: Core Proposition & User Path Optimization (e.g., Weeks 3–6)**
- **Goal:** Clarify who the [SUBJECT] is for, what it does, and why it matters.
- **Key Initiatives:** Refine core messaging, define user profiles, optimize primary user paths and calls-to-action.

**Phase 3: Journey & Experience Enhancement (e.g., Weeks 7–12)**
- **Goal:** Strengthen the end-to-end user journey.
- **Key Initiatives:** Add mid-stage educational content, launch segmented user paths, map roles to journey stages.

**Phase 4: Visibility & Influence (e.g., Months 3–6)**
- **Goal:** Elevate presence and authority in the [DOMAIN].
- **Key Initiatives:** Launch [CONTENT_STRATEGY], publish success stories, engage with the community.

---

### **STEP 8: Final Output Generation**
**Objective:** Synthesize all findings into a comprehensive, layered deliverable accessible to executives, actionable for leaders, and detailed enough for implementation teams.

**8.1 Report Structure (Layered Approach):**
- **Executive Layer (2–3 pages):** For C-suite, investors. Focus on business outcomes, critical issues, and the priority matrix.
- **Strategic Layer (5–7 pages):** For [TARGET_ROLE], project leaders. Focus on root cause analysis, strategic recommendations, and the phased implementation plan.
- **Tactical Layer (Optional):** For implementation teams. Detailed dimension-by-dimension analysis, specific tactical steps.

**8.2 Quality Control Checklist:**
- [ ] Is the executive summary concise and focused on business impact?
- [ ] Are recommendations directly linked to evidence-based root causes?
- [ ] Is the implementation plan realistic, with clear owners and dependencies?
- [ ] Is the deliverable free of jargon and accessible to its target audience?
- [ ] Are all sources properly cited?

---

## SUCCESS METRICS

- **Adherence:** The methodology is followed for all major analysis projects, confirmed by the `orchestrator`.
- **Clarity:** Final reports generated using this framework are rated as "clear and actionable" by >90% of stakeholders.
- **Impact:** At least 75% of "Quick Win" recommendations are implemented within their specified timeframe.
- **Efficiency:** Time from project start to final report delivery is reduced by [TARGET_PERCENTAGE]% over baseline.

---

## QUALITY CHECKLIST

- [ ] All [N] steps of the methodology are present and correctly ordered.
- [ ] All placeholders (e.g., `[PROJECT_NAME]`, `[DOMAIN]`) are populated or clearly marked for population.
- [ ] Terminology is generalized and free of domain-specific jargon (e.g., "marketing").
- [ ] Cross-references to `Evaluation Rubrics` and `Strategic Framework` are correct.
- [ ] The layered reporting structure in Step 8 is clearly defined.
- [ ] The prioritization matrix in Step 6 is explained with clear criteria for Impact and Effort.
- [ ] The document adheres to all MADIO Tier 3 template requirements.
